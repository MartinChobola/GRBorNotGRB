{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7a85fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1665429823563,
     "user": {
      "displayName": "Martin Chobola",
      "userId": "14296412163936900233"
     },
     "user_tz": -120
    },
    "id": "1c7a85fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 12:01:13.189076: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 12:01:13.901180: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-29 12:01:13.901790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-29 12:01:13.936970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:13.937277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 SUPER computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s\n",
      "2023-04-29 12:01:13.937307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:01:13.938658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-29 12:01:13.938694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-29 12:01:13.939854: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-29 12:01:13.940052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-29 12:01:13.941375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-29 12:01:13.942101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-29 12:01:13.944863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-29 12:01:13.944974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:13.945343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:13.945614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "#importing libs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_gen import *\n",
    "from predict_info import *\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Reshape, Dense, Flatten, Input, Conv1D, Conv1DTranspose, MaxPooling1D, UpSampling1D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_curve, confusion_matrix\n",
    "\n",
    "\n",
    "from tensorflow.config.experimental import list_physical_devices, set_virtual_device_configuration, VirtualDeviceConfiguration\n",
    "\n",
    "gpus = list_physical_devices('GPU')\n",
    "set_virtual_device_configuration(gpus[0], [VirtualDeviceConfiguration(memory_limit=4096)])#\n",
    "print(len(gpus), \"Physical GPUs\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a831aac8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 117791,
     "status": "ok",
     "timestamp": 1665158100586,
     "user": {
      "displayName": "Martin Chobola",
      "userId": "14296412163936900233"
     },
     "user_tz": -120
    },
    "id": "a831aac8",
    "outputId": "43ea11e6-018b-4998-9de1-6f985be6d863"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchobola/anaconda3/envs/envi/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>log_cps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>481.489854</td>\n",
       "      <td>0.351577</td>\n",
       "      <td>-0.470408</td>\n",
       "      <td>-0.809389</td>\n",
       "      <td>1.981139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481.489901</td>\n",
       "      <td>0.402253</td>\n",
       "      <td>-0.651949</td>\n",
       "      <td>-0.642771</td>\n",
       "      <td>1.985651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481.489947</td>\n",
       "      <td>0.402425</td>\n",
       "      <td>-0.804490</td>\n",
       "      <td>-0.436865</td>\n",
       "      <td>1.984527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>481.489993</td>\n",
       "      <td>0.359273</td>\n",
       "      <td>-0.910516</td>\n",
       "      <td>-0.204654</td>\n",
       "      <td>2.024280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481.490039</td>\n",
       "      <td>0.284601</td>\n",
       "      <td>-0.957816</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>1.973128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054802</th>\n",
       "      <td>719.491781</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.068985</td>\n",
       "      <td>0.994405</td>\n",
       "      <td>2.120574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054803</th>\n",
       "      <td>719.491793</td>\n",
       "      <td>-0.125928</td>\n",
       "      <td>0.111252</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>2.130334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054804</th>\n",
       "      <td>719.491804</td>\n",
       "      <td>-0.170043</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.973247</td>\n",
       "      <td>2.152288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054805</th>\n",
       "      <td>719.491816</td>\n",
       "      <td>-0.212694</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>0.956851</td>\n",
       "      <td>2.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054806</th>\n",
       "      <td>719.491827</td>\n",
       "      <td>-0.253000</td>\n",
       "      <td>0.242204</td>\n",
       "      <td>0.936658</td>\n",
       "      <td>2.146128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044439 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time         x         y         z   log_cps\n",
       "0        481.489854  0.351577 -0.470408 -0.809389  1.981139\n",
       "1        481.489901  0.402253 -0.651949 -0.642771  1.985651\n",
       "2        481.489947  0.402425 -0.804490 -0.436865  1.984527\n",
       "3        481.489993  0.359273 -0.910516 -0.204654  2.024280\n",
       "4        481.490039  0.284601 -0.957816  0.039879  1.973128\n",
       "...             ...       ...       ...       ...       ...\n",
       "2054802  719.491781 -0.080000  0.068985  0.994405  2.120574\n",
       "2054803  719.491793 -0.125928  0.111252  0.985782  2.130334\n",
       "2054804  719.491804 -0.170043  0.154518  0.973247  2.152288\n",
       "2054805  719.491816 -0.212694  0.197985  0.956851  2.176091\n",
       "2054806  719.491827 -0.253000  0.242204  0.936658  2.146128\n",
       "\n",
       "[2044439 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/scaled_xyzlog_without_GRBs.csv\", index_col=0) # data (hopefuly without grbs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfd2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y_gen(df, windowSize=512):\n",
    "    i = 0\n",
    "    while True:\n",
    "        dfNumpy = df.to_numpy()\n",
    "        if abs(dfNumpy[i+windowSize][0] - (windowSize*(dfNumpy[i-1][0]-dfNumpy[i][0])+dfNumpy[i][0])) < 1:\n",
    "            X = (dfNumpy[i:i+windowSize])\n",
    "            y = (dfNumpy[i+windowSize][-1])\n",
    "        i += 1\n",
    "        yield np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d2a2f8-00d5-4a50-8fe9-086eef753492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df = df[:train_size]\n",
    "val_df = df[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d350fcb",
   "metadata": {
    "id": "3d350fcb"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec6a965-1960-40eb-8986-9e704b0efdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_autoencoder(input_size=512, bottleneck_size=16):\n",
    "    # Define input layer\n",
    "    input_layer = Input(shape=(input_size,1))\n",
    "    normLayer = BatchNormalization()(input_layer)\n",
    "\n",
    "    # Define encoder layers\n",
    "    encoder_layer_1 = Conv1D(filters=512, kernel_size=3, activation='relu', padding='same')(normLayer)\n",
    "    encoder_layer_2 = MaxPooling1D(pool_size=16)(encoder_layer_1)\n",
    "    encoder_layer_3 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(encoder_layer_2)\n",
    "    encoder_layer_4 = MaxPooling1D(pool_size=16)(encoder_layer_3)\n",
    "    encoder_layer_5 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(encoder_layer_4)\n",
    "    bottleneck_layer = Flatten()(encoder_layer_5)\n",
    "    bottleneck_layer = Dense(units=16, activation='relu')(bottleneck_layer)\n",
    "\n",
    "    # Define decoder layers\n",
    "    bottleneck_layer = Dense(units=16, activation='relu')(bottleneck_layer)\n",
    "    reshapeLayer = Reshape((16,1))(bottleneck_layer)\n",
    "    decoder_layer_1 = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(reshapeLayer)\n",
    "    decoder_layer_2 = UpSampling1D(size=16)(decoder_layer_1)\n",
    "    decoder_layer_3 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(decoder_layer_2)\n",
    "    decoder_layer_4 = UpSampling1D(size=16)(decoder_layer_3)\n",
    "    decoder_layer_5 = Conv1D(filters=512, kernel_size=3, activation='relu', padding='same')(decoder_layer_4)\n",
    "    flatLayerDecoder = Flatten()(decoder_layer_5)\n",
    "    outputLayer = Dense(512,activation='relu')(flatLayerDecoder)\n",
    "    outputLayer = Reshape((512,1))(outputLayer)\n",
    "\n",
    "    # Define autoencoder model\n",
    "    autoencoder_model = Model(inputs=input_layer, outputs=outputLayer)\n",
    "\n",
    "    # Compile the autoencoder model\n",
    "    autoencoder_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return autoencoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa289bc-0790-4f00-acc5-82dd64db9cda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-29 12:01:15.181801: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2023-04-29 12:01:15.181818: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2023-04-29 12:01:15.181842: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs\n",
      "2023-04-29 12:01:15.182433: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.10.1\n",
      "2023-04-29 12:01:15.183077: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2023-04-29 12:01:15.183129: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed\n",
      "2023-04-29 12:01:15.190314: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-29 12:01:15.190935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-29 12:01:15.191096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.191423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 SUPER computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s\n",
      "2023-04-29 12:01:15.191471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:01:15.191490: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-29 12:01:15.191505: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-29 12:01:15.191519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-29 12:01:15.191533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-29 12:01:15.191548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-29 12:01:15.191562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-29 12:01:15.191577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-29 12:01:15.191646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.191971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.192250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-04-29 12:01:15.192282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-29 12:01:15.871263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-04-29 12:01:15.871287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-04-29 12:01:15.871292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-04-29 12:01:15.871456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.871823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.872123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-29 12:01:15.872389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2023-04-29 12:01:26.021253: W tensorflow/core/common_runtime/bfc_allocator.cc:433] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.00GiB (rounded to 4294967296)requested by op RandomUniform\n",
      "Current allocation summary follows.\n",
      "2023-04-29 12:01:26.021331: I tensorflow/core/common_runtime/bfc_allocator.cc:972] BFCAllocator dump for GPU_0_bfc\n",
      "2023-04-29 12:01:26.021363: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (256): \tTotal Chunks: 24, Chunks in use: 24. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 968B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021387: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (512): \tTotal Chunks: 2, Chunks in use: 1. 1.2KiB allocated for chunks. 512B in use in bin. 384B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021409: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1024): \tTotal Chunks: 3, Chunks in use: 2. 4.0KiB allocated for chunks. 2.2KiB in use in bin. 2.0KiB client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021430: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2048): \tTotal Chunks: 2, Chunks in use: 2. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 4.0KiB client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021456: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4096): \tTotal Chunks: 3, Chunks in use: 2. 14.2KiB allocated for chunks. 10.0KiB in use in bin. 10.0KiB client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021478: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021502: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16384): \tTotal Chunks: 3, Chunks in use: 2. 72.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021530: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 40.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021571: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021618: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021665: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 1.12MiB allocated for chunks. 768.0KiB in use in bin. 768.0KiB client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021704: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 648.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021737: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021773: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021806: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021849: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021886: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021920: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021953: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.021987: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.022023: I tensorflow/core/common_runtime/bfc_allocator.cc:979] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 4.00GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-04-29 12:01:26.022060: I tensorflow/core/common_runtime/bfc_allocator.cc:995] Bin for 4.00GiB was 256.00MiB, Chunk State: \n",
      "2023-04-29 12:01:26.022148: I tensorflow/core/common_runtime/bfc_allocator.cc:1001]   Size: 4.00GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 384.0KiB | Requested Size: 384.0KiB | in_use: 1 | bin_num: -1\n",
      "2023-04-29 12:01:26.022184: I tensorflow/core/common_runtime/bfc_allocator.cc:1008] Next region of size 4294967296\n",
      "2023-04-29 12:01:26.022217: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000000 of size 256 next 1\n",
      "2023-04-29 12:01:26.022248: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000100 of size 1280 next 2\n",
      "2023-04-29 12:01:26.022280: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000600 of size 256 next 3\n",
      "2023-04-29 12:01:26.022306: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000700 of size 256 next 4\n",
      "2023-04-29 12:01:26.022332: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000800 of size 256 next 5\n",
      "2023-04-29 12:01:26.022368: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000900 of size 256 next 6\n",
      "2023-04-29 12:01:26.022402: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000a00 of size 256 next 7\n",
      "2023-04-29 12:01:26.022428: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc000b00 of size 2048 next 11\n",
      "2023-04-29 12:01:26.022446: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001300 of size 256 next 15\n",
      "2023-04-29 12:01:26.022463: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001400 of size 256 next 16\n",
      "2023-04-29 12:01:26.022479: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001500 of size 256 next 14\n",
      "2023-04-29 12:01:26.022495: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001600 of size 256 next 20\n",
      "2023-04-29 12:01:26.022511: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001700 of size 256 next 21\n",
      "2023-04-29 12:01:26.022527: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001800 of size 256 next 19\n",
      "2023-04-29 12:01:26.022543: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001900 of size 256 next 24\n",
      "2023-04-29 12:01:26.022559: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001a00 of size 256 next 25\n",
      "2023-04-29 12:01:26.022575: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc001b00 of size 256 next 28\n",
      "2023-04-29 12:01:26.022592: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc001c00 of size 1792 next 8\n",
      "2023-04-29 12:01:26.022613: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc002300 of size 256 next 9\n",
      "2023-04-29 12:01:26.022630: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc002400 of size 256 next 10\n",
      "2023-04-29 12:01:26.022646: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc002500 of size 2048 next 42\n",
      "2023-04-29 12:01:26.022663: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc002d00 of size 4352 next 12\n",
      "2023-04-29 12:01:26.022679: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc003e00 of size 6144 next 13\n",
      "2023-04-29 12:01:26.022696: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005600 of size 256 next 29\n",
      "2023-04-29 12:01:26.022712: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005700 of size 256 next 30\n",
      "2023-04-29 12:01:26.022729: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005800 of size 256 next 31\n",
      "2023-04-29 12:01:26.022745: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005900 of size 256 next 36\n",
      "2023-04-29 12:01:26.022762: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005a00 of size 256 next 34\n",
      "2023-04-29 12:01:26.022778: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005b00 of size 256 next 35\n",
      "2023-04-29 12:01:26.022796: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005c00 of size 256 next 32\n",
      "2023-04-29 12:01:26.022813: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc005d00 of size 1024 next 33\n",
      "2023-04-29 12:01:26.022830: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc006100 of size 768 next 37\n",
      "2023-04-29 12:01:26.022847: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc006400 of size 512 next 27\n",
      "2023-04-29 12:01:26.022864: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc006600 of size 4096 next 26\n",
      "2023-04-29 12:01:26.022885: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc007600 of size 40960 next 23\n",
      "2023-04-29 12:01:26.022902: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc011600 of size 24576 next 22\n",
      "2023-04-29 12:01:26.022919: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc017600 of size 24576 next 38\n",
      "2023-04-29 12:01:26.022936: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc01d600 of size 24576 next 39\n",
      "2023-04-29 12:01:26.022952: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc023600 of size 663552 next 18\n",
      "2023-04-29 12:01:26.022969: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc0c5600 of size 393216 next 17\n",
      "2023-04-29 12:01:26.022986: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc125600 of size 393216 next 41\n",
      "2023-04-29 12:01:26.023003: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] InUse at 7f9ccc185600 of size 393216 next 40\n",
      "2023-04-29 12:01:26.023020: I tensorflow/core/common_runtime/bfc_allocator.cc:1028] Free  at 7f9ccc1e5600 of size 4292979200 next 18446744073709551615\n",
      "2023-04-29 12:01:26.023036: I tensorflow/core/common_runtime/bfc_allocator.cc:1033]      Summary of in-use Chunks by size: \n",
      "2023-04-29 12:01:26.023060: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 24 Chunks of size 256 totalling 6.0KiB\n",
      "2023-04-29 12:01:26.023091: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 512 totalling 512B\n",
      "2023-04-29 12:01:26.023109: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 1024 totalling 1.0KiB\n",
      "2023-04-29 12:01:26.023128: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-04-29 12:01:26.023146: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 2048 totalling 4.0KiB\n",
      "2023-04-29 12:01:26.023165: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 4096 totalling 4.0KiB\n",
      "2023-04-29 12:01:26.023183: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2023-04-29 12:01:26.023202: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 24576 totalling 48.0KiB\n",
      "2023-04-29 12:01:26.023222: I tensorflow/core/common_runtime/bfc_allocator.cc:1036] 2 Chunks of size 393216 totalling 768.0KiB\n",
      "2023-04-29 12:01:26.023242: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Sum Total of in-use chunks: 838.8KiB\n",
      "2023-04-29 12:01:26.023260: I tensorflow/core/common_runtime/bfc_allocator.cc:1042] total_region_allocated_bytes_: 4294967296 memory_limit_: 4294967296 available bytes: 0 curr_region_allocation_bytes_: 8589934592\n",
      "2023-04-29 12:01:26.023293: I tensorflow/core/common_runtime/bfc_allocator.cc:1048] Stats: \n",
      "Limit:                      4294967296\n",
      "InUse:                          858880\n",
      "MaxInUse:                      1913600\n",
      "NumAllocs:                          59\n",
      "MaxAllocSize:                   663552\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-04-29 12:01:26.023321: W tensorflow/core/common_runtime/bfc_allocator.cc:441] *___________________________________________________________________________________________________\n",
      "2023-04-29 12:01:26.023375: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at random_op.cc:74 : Resource exhausted: OOM when allocating tensor with shape[2097152,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[2097152,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m fileName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mmonth,\n\u001b[1;32m      2\u001b[0m           datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mday,\n\u001b[1;32m      3\u001b[0m           datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mhour,\n\u001b[1;32m      4\u001b[0m           datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mtoday()\u001b[38;5;241m.\u001b[39mminute)\n\u001b[1;32m      5\u001b[0m callback_conv \u001b[38;5;241m=\u001b[39m [EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m),\n\u001b[1;32m      6\u001b[0m                  ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/autoConv/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fileName), \n\u001b[1;32m      7\u001b[0m                                  monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m),\n\u001b[1;32m     12\u001b[0m                 TensorBoard(log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Tensor_logs/auto/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fileName), update_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m---> 13\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     15\u001b[0m history \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mfit(df_to_X_y_gen(train_df),\n\u001b[1;32m     16\u001b[0m           validation_data \u001b[38;5;241m=\u001b[39m (df_to_X_y_gen(val_df)),\n\u001b[1;32m     17\u001b[0m           epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[callback_conv])\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mcreate_autoencoder\u001b[0;34m(input_size, bottleneck_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m decoder_layer_5 \u001b[38;5;241m=\u001b[39m Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(decoder_layer_4)\n\u001b[1;32m     23\u001b[0m flatLayerDecoder \u001b[38;5;241m=\u001b[39m Flatten()(decoder_layer_5)\n\u001b[0;32m---> 24\u001b[0m outputLayer \u001b[38;5;241m=\u001b[39m \u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflatLayerDecoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m outputLayer \u001b[38;5;241m=\u001b[39m Reshape((\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m1\u001b[39m))(outputLayer)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Define autoencoder model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:951\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _in_functional_construction_mode(\u001b[38;5;28mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 951\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional_construction_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43minput_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m call_context \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:1090\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keras_tensor\u001b[38;5;241m.\u001b[39mkeras_tensors_enabled():\n\u001b[1;32m   1087\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m call_context\u001b[38;5;241m.\u001b[39menter(\n\u001b[1;32m   1088\u001b[0m       layer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, inputs\u001b[38;5;241m=\u001b[39minputs, build_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39mtraining_value):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;66;03m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1090\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_tensor_symbolic_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA layer\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms `call` method should return a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1095\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor or a list of Tensors, not None \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1096\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(layer: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:822\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mmap_structure(keras_tensor\u001b[38;5;241m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 822\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_output_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:862\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_scope()):\n\u001b[1;32m    857\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    858\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Build layer if applicable (if the `build` method has been\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# overridden).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(inputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:2710\u001b[0m, in \u001b[0;36mLayer._maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   2706\u001b[0m   \u001b[38;5;66;03m# Any setup work performed only once should happen in an `init_scope`\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m   \u001b[38;5;66;03m# to avoid creating symbolic Tensors that will later pollute any eager\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m   \u001b[38;5;66;03m# operations.\u001b[39;00m\n\u001b[1;32m   2709\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mmaybe_init_scope(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint:disable=not-callable\u001b[39;00m\n\u001b[1;32m   2711\u001b[0m \u001b[38;5;66;03m# We must set also ensure that the layer is marked as built, and the build\u001b[39;00m\n\u001b[1;32m   2712\u001b[0m \u001b[38;5;66;03m# shape is stored since user defined build functions may not be calling\u001b[39;00m\n\u001b[1;32m   2713\u001b[0m \u001b[38;5;66;03m# `super.build()`\u001b[39;00m\n\u001b[1;32m   2714\u001b[0m Layer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m, input_shapes)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py:1185\u001b[0m, in \u001b[0;36mDense.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe last dimension of the inputs to `Dense` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1183\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould be defined. Found `None`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m InputSpec(min_ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: last_dim})\n\u001b[0;32m-> 1185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weight\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkernel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlast_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias:\n\u001b[1;32m   1194\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_weight(\n\u001b[1;32m   1195\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1196\u001b[0m       shape\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits,],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1200\u001b[0m       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1201\u001b[0m       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py:623\u001b[0m, in \u001b[0;36mLayer.add_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m     tf_logging\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`caching_device` does not work with mixed precision \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    620\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI. Ignoring user specified `caching_device`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    621\u001b[0m     caching_device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_variable_with_custom_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(allenl): a `make_variable` equivalent should be added as a\u001b[39;49;00m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Trackable` method.\u001b[39;49;00m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgetter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Manage errors in Layer rather than Trackable.\u001b[39;49;00m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regularizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m   \u001b[38;5;66;03m# TODO(fchollet): in the future, this should be handled at the\u001b[39;00m\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;66;03m# level of variable creation, and weight regularization losses\u001b[39;00m\n\u001b[1;32m    643\u001b[0m   \u001b[38;5;66;03m# should be variable attributes.\u001b[39;00m\n\u001b[1;32m    644\u001b[0m   name_in_scope \u001b[38;5;241m=\u001b[39m variable\u001b[38;5;241m.\u001b[39mname[:variable\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:805\u001b[0m, in \u001b[0;36mTrackable._add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    795\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (checkpoint_initializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    796\u001b[0m       \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(initializer, CheckpointInitialValueCallable) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    797\u001b[0m            (initializer\u001b[38;5;241m.\u001b[39mrestore_uid \u001b[38;5;241m>\u001b[39m checkpoint_initializer\u001b[38;5;241m.\u001b[39mrestore_uid))):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# then we'll catch that when we call _track_trackable. So this is\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;66;03m# \"best effort\" to set the initializer with the highest restore UID.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m     initializer \u001b[38;5;241m=\u001b[39m checkpoint_initializer\n\u001b[0;32m--> 805\u001b[0m new_variable \u001b[38;5;241m=\u001b[39m \u001b[43mgetter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_for_getter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# If we set an initializer and the variable processed it, tracking will not\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# assign again. It will add this variable to our dependencies, and if there\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;66;03m# is a non-trivial restoration queued, it will handle that. This also\u001b[39;00m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;66;03m# handles slot variables.\u001b[39;00m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_variable, Trackable):\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_utils.py:130\u001b[0m, in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# TODO(apassos,rohanj) figure out how to remove collections from here so we\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# can remove the V1.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m variable_shape \u001b[38;5;241m=\u001b[39m tensor_shape\u001b[38;5;241m.\u001b[39mTensorShape(shape)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_variables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariableV1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvariable_shape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:260\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m VariableV1:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_v1_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Variable:\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:206\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    205\u001b[0m   aggregation \u001b[38;5;241m=\u001b[39m VariableAggregation\u001b[38;5;241m.\u001b[39mNONE\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprevious_getter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_resource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:199\u001b[0m, in \u001b[0;36mVariableMetaclass._variable_v1_call.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_variable_v1_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m    183\u001b[0m                       initial_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m                       trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m                       aggregation\u001b[38;5;241m=\u001b[39mVariableAggregation\u001b[38;5;241m.\u001b[39mNONE,\n\u001b[1;32m    197\u001b[0m                       shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;124;03m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m   previous_getter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mdefault_variable_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _, getter \u001b[38;5;129;01min\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\u001b[38;5;241m.\u001b[39m_variable_creator_stack:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     previous_getter \u001b[38;5;241m=\u001b[39m _make_getter(getter, previous_getter)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py:2604\u001b[0m, in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_resource:\n\u001b[1;32m   2603\u001b[0m   distribute_strategy \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistribute_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 2604\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2609\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2610\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvariable_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariable_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[43m      \u001b[49m\u001b[43mimport_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimport_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2620\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mRefVariable(\n\u001b[1;32m   2621\u001b[0m       initial_value\u001b[38;5;241m=\u001b[39minitial_value,\n\u001b[1;32m   2622\u001b[0m       trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2633\u001b[0m       aggregation\u001b[38;5;241m=\u001b[39maggregation,\n\u001b[1;32m   2634\u001b[0m       shape\u001b[38;5;241m=\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/variables.py:264\u001b[0m, in \u001b[0;36mVariableMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_v2_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVariableMetaclass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1574\u001b[0m, in \u001b[0;36mResourceVariable.__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_from_proto(variable_def, import_scope\u001b[38;5;241m=\u001b[39mimport_scope)\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_from_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcollections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaching_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaching_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m      \u001b[49m\u001b[43mconstraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m      \u001b[49m\u001b[43msynchronization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m      \u001b[49m\u001b[43maggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:1712\u001b[0m, in \u001b[0;36mResourceVariable._init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializer\u001b[39m\u001b[38;5;124m\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1711\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[0;32m-> 1712\u001b[0m     initial_value \u001b[38;5;241m=\u001b[39m \u001b[43minitial_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1713\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(initial_value, trackable\u001b[38;5;241m.\u001b[39mCheckpointInitialValue):\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py:409\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    399\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a tensor object initialized as specified by the initializer.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    **kwargs: Additional keyword arguments.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mVarianceScaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:600\u001b[0m, in \u001b[0;36mVarianceScaling.__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m   limit \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m \u001b[38;5;241m*\u001b[39m scale)\n\u001b[0;32m--> 600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_random_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py:1081\u001b[0m, in \u001b[0;36m_RandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1080\u001b[0m   op \u001b[38;5;241m=\u001b[39m random_ops\u001b[38;5;241m.\u001b[39mrandom_uniform\n\u001b[0;32m-> 1081\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py:302\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    299\u001b[0m   result \u001b[38;5;241m=\u001b[39m gen_random_ops\u001b[38;5;241m.\u001b[39mrandom_uniform_int(\n\u001b[1;32m    300\u001b[0m       shape, minval, maxval, seed\u001b[38;5;241m=\u001b[39mseed1, seed2\u001b[38;5;241m=\u001b[39mseed2, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_random_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m minval_is_zero:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m maxval_is_one:\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/ops/gen_random_ops.py:721\u001b[0m, in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    719\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 721\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m    723\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/envi/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6862\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m message \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6861\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6862\u001b[0m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2097152,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "fileName = '{}-{}-{}-{}'.format(datetime.datetime.today().month,\n",
    "          datetime.datetime.today().day,\n",
    "          datetime.datetime.today().hour,\n",
    "          datetime.datetime.today().minute)\n",
    "callback_conv = [EarlyStopping(monitor='val_loss', patience=7),\n",
    "                 ModelCheckpoint(\"models/autoConv/{}.h5\".format(fileName), \n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True, \n",
    "                                 mode='min'),\n",
    "                ReduceLROnPlateau(monitor='val_loss',factor=0.7,patience=3,verbose=True,min_lr=0.000001),\n",
    "                TensorBoard(log_dir = \"./Tensor_logs/auto/{}\".format(fileName), update_freq=\"epoch\")]\n",
    "autoencoder = create_autoencoder()\n",
    "autoencoder.summary()\n",
    "history = autoencoder.fit(df_to_X_y_gen(train_df),\n",
    "          validation_data = (df_to_X_y_gen(val_df)),\n",
    "          epochs=100, callbacks=[callback_conv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e77b8-6c80-4cdf-8add-4eec3f001a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd480231",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 934
    },
    "executionInfo": {
     "elapsed": 3477,
     "status": "ok",
     "timestamp": 1665158323104,
     "user": {
      "displayName": "Martin Chobola",
      "userId": "14296412163936900233"
     },
     "user_tz": -120
    },
    "id": "cd480231",
    "outputId": "3c8da909-3045-4e83-d4bb-638f2882d6fb"
   },
   "outputs": [],
   "source": [
    "X_pred = autoencoder.predict(X_test)\n",
    "x = np.arange(len(X_test[0]))\n",
    "fig, axs = plt.subplots(5,5,figsize=(16,16))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ind = np.random.randint(len(y_test))\n",
    "        axs[i,j].set_title(y_test[ind])\n",
    "        axs[i,j].step(x,X_test[ind])\n",
    "        axs[i,j].step(x,X_pred[ind],color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.save(\"autoencoder_conv1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8958c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
