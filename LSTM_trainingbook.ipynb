{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8883,
     "status": "ok",
     "timestamp": 1677969275021,
     "user": {
      "displayName": "Martin Chobola",
      "userId": "14296412163936900233"
     },
     "user_tz": -60
    },
    "id": "iaeU0RQqk1Rq",
    "outputId": "d115ba35-09fd-4b8c-f1fb-6f03d9749566"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:14:31.299774: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:14:34.093920: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-09 13:14:34.105320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-09 13:14:34.195955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-09 13:14:34.196553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 SUPER computeCapability: 7.5\n",
      "coreClock: 1.83GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s\n",
      "2023-04-09 13:14:34.196587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-09 13:14:34.287925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-09 13:14:34.288170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-09 13:14:34.339631: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-09 13:14:34.352442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-09 13:14:34.450051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-09 13:14:34.461976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-09 13:14:34.640418: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-09 13:14:34.640880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-09 13:14:34.642497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-09 13:14:34.643771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.time import Time\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.metrics import MeanSquaredError, MeanAbsoluteError, RootMeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.config.experimental import list_physical_devices, set_virtual_device_configuration, VirtualDeviceConfiguration\n",
    "\n",
    "gpus = list_physical_devices('GPU')\n",
    "set_virtual_device_configuration(gpus[0], [VirtualDeviceConfiguration(memory_limit=1200)])\n",
    "print(len(gpus), \"Physical GPUs\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchobola/anaconda3/envs/envi/lib/python3.9/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>log_cps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>481.489854</td>\n",
       "      <td>0.351577</td>\n",
       "      <td>-0.470408</td>\n",
       "      <td>-0.809389</td>\n",
       "      <td>1.981139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>481.489901</td>\n",
       "      <td>0.402253</td>\n",
       "      <td>-0.651949</td>\n",
       "      <td>-0.642771</td>\n",
       "      <td>1.985651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>481.489947</td>\n",
       "      <td>0.402425</td>\n",
       "      <td>-0.804490</td>\n",
       "      <td>-0.436865</td>\n",
       "      <td>1.984527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>481.489993</td>\n",
       "      <td>0.359273</td>\n",
       "      <td>-0.910516</td>\n",
       "      <td>-0.204654</td>\n",
       "      <td>2.024280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481.490039</td>\n",
       "      <td>0.284601</td>\n",
       "      <td>-0.957816</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>1.973128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054802</th>\n",
       "      <td>719.491781</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>0.068985</td>\n",
       "      <td>0.994405</td>\n",
       "      <td>2.120574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054803</th>\n",
       "      <td>719.491793</td>\n",
       "      <td>-0.125928</td>\n",
       "      <td>0.111252</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>2.130334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054804</th>\n",
       "      <td>719.491804</td>\n",
       "      <td>-0.170043</td>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.973247</td>\n",
       "      <td>2.152288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054805</th>\n",
       "      <td>719.491816</td>\n",
       "      <td>-0.212694</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>0.956851</td>\n",
       "      <td>2.176091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054806</th>\n",
       "      <td>719.491827</td>\n",
       "      <td>-0.253000</td>\n",
       "      <td>0.242204</td>\n",
       "      <td>0.936658</td>\n",
       "      <td>2.146128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044439 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time         x         y         z   log_cps\n",
       "0        481.489854  0.351577 -0.470408 -0.809389  1.981139\n",
       "1        481.489901  0.402253 -0.651949 -0.642771  1.985651\n",
       "2        481.489947  0.402425 -0.804490 -0.436865  1.984527\n",
       "3        481.489993  0.359273 -0.910516 -0.204654  2.024280\n",
       "4        481.490039  0.284601 -0.957816  0.039879  1.973128\n",
       "...             ...       ...       ...       ...       ...\n",
       "2054802  719.491781 -0.080000  0.068985  0.994405  2.120574\n",
       "2054803  719.491793 -0.125928  0.111252  0.985782  2.130334\n",
       "2054804  719.491804 -0.170043  0.154518  0.973247  2.152288\n",
       "2054805  719.491816 -0.212694  0.197985  0.956851  2.176091\n",
       "2054806  719.491827 -0.253000  0.242204  0.936658  2.146128\n",
       "\n",
       "[2044439 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/scaled_xyzlog_without_GRBs.csv\", index_col=0) # data (hopefuly without grbs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(df, windowSize=128):\n",
    "    dfNumpy = df.to_numpy()\n",
    "    X,y = [], []\n",
    "    for i in range(len(dfNumpy)-windowSize):\n",
    "        if abs(dfNumpy[i+windowSize][0] - (windowSize*(dfNumpy[i-1][0]-dfNumpy[i][0])+dfNumpy[i][0])) < 1:\n",
    "            X.append(dfNumpy[i:i+windowSize])\n",
    "            y.append(dfNumpy[i+windowSize][-1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def lossPlot(history,name,figsize=(5,3)):\n",
    "    t_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(t_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.yscale(\"log\")\n",
    "    plt.savefig('loss_{}.png'.format(name))\n",
    "    \n",
    "def isModelGood(model,name):\n",
    "    grbs = glob.glob(\"Data/scaled_xyzlog/*.csv\")\n",
    "    n_grbs = len(grbs)\n",
    "    fig, axs = plt.subplots(n_grbs,5,figsize=(30,3*n_grbs))\n",
    "    for n , grb in enumerate(grbs):\n",
    "        df = pd.read_csv(grb, index_col=0)\n",
    "        num_df = df.to_numpy()\n",
    "        df = df.drop(['0'],axis=1)\n",
    "        y_pred0 = []\n",
    "        X0 = df[:windowSize].copy().to_numpy()\n",
    "        for i in range(len(df)-windowSize):\n",
    "            pred = model.predict(X0.reshape(1,windowSize,4))[0]\n",
    "            y_pred0.append(pred)\n",
    "            X0 = df[i+1:i+windowSize+1].copy().to_numpy()\n",
    "            X0[:,-1] = pred\n",
    "            \n",
    "        true_lc = 10**(np.array(num_df[windowSize:,-1]))\n",
    "        pred_lc = 10**(np.array(y_pred0).T[0])\n",
    "        \n",
    "        axs[n,0].hist(true_lc-pred_lc)\n",
    "        \n",
    "        axs[n,1].plot(true_lc)\n",
    "        axs[n,1].plot(pred_lc)\n",
    "        \n",
    "        axs[n,2].plot(true_lc[:10])\n",
    "        axs[n,2].plot(pred_lc[:10]) \n",
    "        \n",
    "        axs[n,3].plot(true_lc[-64:])\n",
    "        axs[n,3].plot(pred_lc[-64:])\n",
    "        \n",
    "        axs[n,4].plot((true_lc-pred_lc)/true_lc)\n",
    "    fig.savefig('LSTM_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def training_LSTM(df, windowSize,n_neuro_LSTM,n_neuro_dense,n_layers,n_output,loss,metrics):\n",
    "    fileName = '{}-{}-{}-{}-{}-{}'.format(windowSize,n_neuro_LSTM,n_neuro_dense,n_layers,loss.__class__.__name__,metrics.__class__.__name__)\n",
    "    print(fileName)\n",
    "    X1, y1 = df_to_X_y(df, windowSize)\n",
    "    splitIndex = int(len(df) * 0.8)\n",
    "    X_train, y_train, X_test, y_test = X1[0:splitIndex,:,1:],y1[0:splitIndex],X1[splitIndex:,:,1:],y1[splitIndex:]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(InputLayer((windowSize,4)))\n",
    "    model.add(LSTM(n_neuro_LSTM))\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(n_neuro_dense, 'relu'))\n",
    "    model.add(Dense(n_output, 'linear'))\n",
    "    \n",
    "    model.compile(loss=loss,\n",
    "                   optimizer=Adam(learning_rate=0.01),\n",
    "                   metrics=metrics)\n",
    "\n",
    "    #EarlyStopping(monitor='val_loss', patience=5)\n",
    "    #ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=3,verbose=True,min_lr=0.00001)\n",
    "    callback = [ModelCheckpoint(\"models/LSTM_{}.h5\".format(fileName), \n",
    "                                 monitor='val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True, \n",
    "                                 mode='min'),\n",
    "               TensorBoard(log_dir=\"Tensor_logs\")]\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50,callbacks=[callback])\n",
    "    lossPlot(history,fileName)\n",
    "    isModelGood(model,fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128-64-16-7-MeanSquaredError-MeanSquaredError\n"
     ]
    }
   ],
   "source": [
    "# def training_LSTM(df, windowSize,n_neuro_LSTM,n_neuro_dense,n_layers,n_output,loss,metrics):\n",
    "\n",
    "win = [128]\n",
    "n_neuro_LSTM = [64]\n",
    "n_neuro_dense = [16,32]\n",
    "n_layers = [7,5,3]\n",
    "losses = [MeanSquaredError()]#,MeanAbsoluteError()]\n",
    "metrics = [MeanSquaredError()] #MeanAbsoluteError()\n",
    "for window in win:\n",
    "    for n in n_neuro_LSTM:\n",
    "        for nn in n_neuro_dense:\n",
    "            for nnn in n_layers:\n",
    "                for loss in losses:\n",
    "                    for metric in metrics:\n",
    "                        training_LSTM(df,window,n,nn,nnn,1,loss,metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIr5XYq+Z2oRHmnZLamHFM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
